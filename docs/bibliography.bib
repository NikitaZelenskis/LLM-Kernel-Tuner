@article{BatFix,
author = {Ramos, Daniel and Lynce, In\^{e}s and Manquinho, Vasco and Martins, Ruben and Le Goues, Claire},
title = {BatFix: Repairing language model-based transpilation},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3658668},
doi = {10.1145/3658668},
abstract = {To keep up with changes in requirements, frameworks, and coding practices, software organizations might need to migrate code from one language to another. Source-to-source migration, or transpilation, is often a complex, manual process. Transpilation requires expertise both in the source and target language, making it highly laborious and costly. Languages models for code generation and transpilation are becoming increasingly popular. However, despite capturing code-structure well, code generated by language models is often spurious and contains subtle problems. We propose BatFix, a novel approach that augments language models for transpilation by leveraging program repair and synthesis to fix the code generated by these models. BatFix takes as input both the original program, the target program generated by the machine translation model, and a set of test cases and outputs a repaired program that passes all test cases. Experimental results show that our approach is agnostic to language models and programming languages. BatFix can locate bugs spawning multiple lines and synthesize patches for syntax and semantic bugs for programs migrated from Java to C++ and Python to C++ from multiple language models, including, OpenAI’s Codex.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {apr},
keywords = {Program Analysis, Automated Refactoring, Machine Learning, Transpilation}
}

@misc{yang2024vert,
      title={VERT: Verified Equivalent Rust Transpilation with Few-Shot Learning}, 
      author={Aidan Z. H. Yang and Yoshiki Takashima and Brandon Paulsen and Josiah Dodds and Daniel Kroening},
      year={2024},
      eprint={2404.18852},
      archivePrefix={arXiv},
      primaryClass={cs.PL}
}

@misc{döderlein2023piloting,
      title={Piloting Copilot and Codex: Hot Temperature, Cold Prompts, or Black Magic?}, 
      author={Jean-Baptiste Döderlein and Mathieu Acher and Djamel Eddine Khelladi and Benoit Combemale},
      year={2023},
      eprint={2210.14699},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@misc{he2023large,
      title={Large Language Models for Code: Security Hardening and Adversarial Testing}, 
      author={Jingxuan He and Martin Vechev},
      year={2023},
      eprint={2302.05319},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

@misc{white2023chatgpt,
      title={ChatGPT Prompt Patterns for Improving Code Quality, Refactoring, Requirements Elicitation, and Software Design}, 
      author={Jules White and Sam Hays and Quchen Fu and Jesse Spencer-Smith and Douglas C. Schmidt},
      year={2023},
      eprint={2303.07839},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@misc{yan2023coco,
      title={COCO: Testing Code Generation Systems via Concretized Instructions}, 
      author={Ming Yan and Junjie Chen and Jie M. Zhang and Xuejie Cao and Chen Yang and Mark Harman},
      year={2023},
      eprint={2308.13319},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@misc{chen2022codet,
      title={CodeT: Code Generation with Generated Tests}, 
      author={Bei Chen and Fengji Zhang and Anh Nguyen and Daoguang Zan and Zeqi Lin and Jian-Guang Lou and Weizhu Chen},
      year={2022},
      eprint={2207.10397},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{li2023acecoder,
      title={AceCoder: Utilizing Existing Code to Enhance Code Generation}, 
      author={Jia Li and Yunfei Zhao and Yongmin Li and Ge Li and Zhi Jin},
      year={2023},
      eprint={2303.17780},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@article{kerneltuner,
  author  = {Ben van Werkhoven},
  title   = {Kernel Tuner: A search-optimizing GPU code auto-tuner},
  journal = {Future Generation Computer Systems},
  year = {2019},
  volume  = {90},
  pages = {347-358},
  url = {https://www.sciencedirect.com/science/article/pii/S0167739X18313359},
  doi = {https://doi.org/10.1016/j.future.2018.08.004}
}


@misc{li2024needlebenchllmsretrievalreasoning,
      title={NeedleBench: Can LLMs Do Retrieval and Reasoning in 1 Million Context Window?}, 
      author={Mo Li and Songyang Zhang and Yunxin Liu and Kai Chen},
      year={2024},
      eprint={2407.11963},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.11963}, 
}

@misc{yu2025longcontextlanguagemodelsgood,
      title={Long-context Language Models Are Not Good At ALL Retrieval Tasks Without Sufficient Steps}, 
      author={Yijiong Yu and Ma Xiufa and Fang Jianwei and Zhi Xu and Su Guangyao and Wang Jiancheng and Yongfeng Huang and Zhixiao Qi and Wei Wang and Weifeng Liu and Ran Chen and Ji Pei},
      year={2025},
      eprint={2410.04422},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.04422}, 
}

@misc{langchain_multi_needle_benc,
    title={Multi Needle in a Haystack},
    author={LangChain},
    year={2024},
    url={https://blog.langchain.dev/multi-needle-in-a-haystack/}

}

@misc{wei2023chainofthoughtpromptingelicitsreasoning,
      title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models}, 
      author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
      year={2023},
      eprint={2201.11903},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2201.11903}, 
}

@misc{modarressi2025nolimalongcontextevaluationliteral,
      title={NoLiMa: Long-Context Evaluation Beyond Literal Matching}, 
      author={Ali Modarressi and Hanieh Deilamsalehy and Franck Dernoncourt and Trung Bui and Ryan A. Rossi and Seunghyun Yoon and Hinrich Schütze},
      year={2025},
      eprint={2502.05167},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.05167}, 
}

@article{Bal2016,
  author    = {Henri Bal and Dick Epema and Cees de Laat and Rob van Nieuwpoort and John Romein and Frank Seinstra and Cees Snoek and Harry Wijshoff},
  title     = {A Medium-Scale Distributed System for Computer Science Research: Infrastructure for the Long Term},
  journal   = {IEEE Computer},
  volume    = {49},
  number    = {5},
  pages     = {54--63},
  month     = {May},
  year      = {2016},
  doi       = {10.1109/MC.2016.142}
}

@misc{wang2023planandsolvepromptingimprovingzeroshot,
      title={Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models}, 
      author={Lei Wang and Wanyu Xu and Yihuai Lan and Zhiqiang Hu and Yunshi Lan and Roy Ka-Wei Lee and Ee-Peng Lim},
      year={2023},
      eprint={2305.04091},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.04091}, 
}
@inproceedings{NEURIPS2023_43e9d647,
 author = {Liu, Jiawei and Xia, Chunqiu Steven and Wang, Yuyao and ZHANG, LINGMING},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {21558--21572},
 publisher = {Curran Associates, Inc.},
 title = {Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/43e9d647ccd3e4b7b5baab53f0368686-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}

@article{10.1145/3643769,
author = {Ryan, Gabriel and Jain, Siddhartha and Shang, Mingyue and Wang, Shiqi and Ma, Xiaofei and Ramanathan, Murali Krishna and Ray, Baishakhi},
title = {Code-Aware Prompting: A Study of Coverage-Guided Test Generation in Regression Setting using LLM},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3643769},
doi = {10.1145/3643769},
abstract = {Testing plays a pivotal role in ensuring software quality, yet conventional Search Based Software Testing (SBST) methods often struggle with complex software units, achieving suboptimal test coverage. Recent work using large language models (LLMs) for test generation have focused on improving generation quality through optimizing the test generation context and correcting errors in model outputs, but use fixed prompting strategies that prompt the model to generate tests without additional guidance. As a result LLM-generated testsuites still suffer from low coverage. 

In this paper, we present SymPrompt, a code-aware prompting strategy for LLMs in test generation. SymPrompt’s approach is based on recent work that demonstrates LLMs can solve more complex logical problems when prompted to reason about the problem in a multi-step fashion. We apply this methodology to test generation by deconstructing the testsuite generation process into a multi-stage sequence, each of which is driven by a specific prompt aligned with the execution paths of the method under test, and exposing relevant type and dependency focal context to the model. Our approach enables pretrained LLMs to generate more complete test cases without any additional training. We implement SymPrompt using the TreeSitter parsing framework and evaluate on a benchmark challenging methods from open source Python projects. SymPrompt enhances correct test generations by a factor of 5 and bolsters relative coverage by 26\% for CodeGen2. Notably, when applied to GPT-4, SymPrompt improves coverage by over 2x compared to baseline prompting strategies.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {43},
numpages = {21},
keywords = {Large Language Models, Test Generation}
}


@misc{chiang2024chatbotarenaopenplatform,
      title={Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference}, 
      author={Wei-Lin Chiang and Lianmin Zheng and Ying Sheng and Anastasios Nikolas Angelopoulos and Tianle Li and Dacheng Li and Hao Zhang and Banghua Zhu and Michael Jordan and Joseph E. Gonzalez and Ion Stoica},
      year={2024},
      eprint={2403.04132},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2403.04132}, 
}


@misc{zhang2023repocoderrepositorylevelcodecompletion,
      title={RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation}, 
      author={Fengji Zhang and Bei Chen and Yue Zhang and Jacky Keung and Jin Liu and Daoguang Zan and Yi Mao and Jian-Guang Lou and Weizhu Chen},
      year={2023},
      eprint={2303.12570},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.12570}, 
}